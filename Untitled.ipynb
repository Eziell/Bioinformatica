{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions defining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Functions\n",
    "import json\n",
    "import requests\n",
    "\n",
    "\n",
    "def get_Full_Description(uniprot_id):\n",
    "\n",
    "    #Get the Uniprot data\n",
    "    response = requests.get('http://www.uniprot.org/uniprot/' + uniprot_id + '.txt')\n",
    "    data = response.text\n",
    "    \n",
    "    return data\n",
    "\n",
    "def xml_get_NucleotideVar(uniprot_id):\n",
    "    \n",
    "    #Get the Uniprot data in xml\n",
    "    response = requests.get('http://www.uniprot.org/uniprot/' + uniprot_id + '.xml')\n",
    "    data = response.text\n",
    "    \n",
    "def get_NucleotideVar(uniprot_id):\n",
    "\n",
    "    #Get the Uniprot data\n",
    "    response = requests.get('http://www.uniprot.org/uniprot/' + uniprot_id + '.txt')\n",
    "    data = response.text\n",
    "    data_lines = data.splitlines()\n",
    "    \n",
    "    # Look for the RP identifiers followed by NUCLEOTIDE SEQUENCE\n",
    "    rp_ids = set()\n",
    "    for line in data_lines:\n",
    "        if line.startswith('RP') and \"VARIANT\" in line:\n",
    "            rp_ids.add(line)\n",
    "    \n",
    "    return \"\\n\".join(rp_ids)\n",
    "\n",
    "def get_full_annotation(uniprot_id):\n",
    "    distinct_terms = set()\n",
    "    \n",
    "    # First get the Uniprot data\n",
    "    response = requests.get('http://www.uniprot.org/uniprot/' + uniprot_id + '.txt')\n",
    "    data = response.text\n",
    "    data_lines = data.splitlines()\n",
    "    \n",
    "    # Look for the GO identifiers in the response and save them in a set\n",
    "    go_ids = set()\n",
    "    for line in data_lines:\n",
    "        if line.startswith('DR   GO'):\n",
    "            line_prefix, go_id, go_term_full, evidence_code = line.split(';')\n",
    "            go_id = go_id.strip()\n",
    "            go_ids.add(go_id)\n",
    "    \n",
    "    # Construct the URL for the QuickGO Request with all those GO identifiers\n",
    "    the_url = 'https://www.ebi.ac.uk/QuickGO/services/ontology/go/terms/'\n",
    "    the_url += ','.join(go_ids)\n",
    "    the_url += '/ancestors?relations=is_a'\n",
    "    \n",
    "    # Make the request and parse the results\n",
    "    response = requests.get(the_url)\n",
    "    anc_data = json.loads(response.text)\n",
    "    results = anc_data['results']\n",
    "    for record in results:\n",
    "        distinct_terms.update(record['ancestors'])\n",
    "                                        \n",
    "    return distinct_terms\n",
    "\n",
    "def get_term_info(go_id):\n",
    "    the_url = 'https://www.ebi.ac.uk/QuickGO/services/ontology/go/terms/' + go_id\n",
    "    response = requests.get(the_url)\n",
    "    data = json.loads(response.text)\n",
    "    \n",
    "    record = data['results'][0] # Get the first result, because we are only requesting one!\n",
    "    \n",
    "    # Return a dictionary that contains the information of this GO term\n",
    "    go_info = {\n",
    "        'go_id': record['id'],\n",
    "        'aspect': record['aspect'],\n",
    "        'name': record['name'],\n",
    "        'definition': record['definition']['text'],\n",
    "        'obsolete': record['isObsolete'],\n",
    "    }\n",
    "    \n",
    "    return go_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entries on the uniprot database downloaded manually therefore the first step is open the .fasta file.\n",
    "The file is going to be opened with SeqIO function parse that is going to format the output accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Bio'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-dc759f5f2e7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mBio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSeqIO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mOMIM\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"uniprot-database_(type_mim+168600).fasta\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mparkinson_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeqIO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOMIM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'fasta'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Bio'"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "import requests\n",
    "\n",
    "OMIM=\"uniprot-database_(type_mim+168600).fasta\"\n",
    "parkinson_sequences = SeqIO.parse(open(OMIM),'fasta')\n",
    "proteins=[]\n",
    "all_terms=[]\n",
    "#opening proteins.tsv for writting procedures.\n",
    "f = open('proteins.tsv', \"w\")\n",
    "\n",
    "#retrieving protein names and IDs\n",
    "f.write(str(\"Retrieving protein names and IDs from \"+ OMIM + \"\\n\"))\n",
    "f.write(str(\"ProteinName\\tProteinID\\n\"))\n",
    "with open(OMIM) as out_file:\n",
    "    for fasta in parkinson_sequences:\n",
    "        name, sequence, = fasta.id, str(fasta.seq)\n",
    "        id = name.split(\"|\")\n",
    "        #retrieving gene\n",
    "        f.write(str(id[2]+\"\\t\"+id[1]+\"\\n\"))\n",
    "        proteins.append(id[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GO ID analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'proteins' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-de24e561bdcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#GO term counting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mall_terms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mprotein_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproteins\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mall_terms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniRetrieval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_full_annotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotein_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'proteins' is not defined"
     ]
    }
   ],
   "source": [
    "import uniRetrieval\n",
    "#GO term counting \n",
    "all_terms = []\n",
    "for protein_id in proteins:\n",
    "    all_terms.extend(uniRetrieval.get_full_annotation(protein_id))\n",
    "\n",
    "term_counts = {term: all_terms.count(term) for term in all_terms}\n",
    "distinct_terms = list(term_counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
